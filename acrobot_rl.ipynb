{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CevNT10U8ii8",
        "outputId": "3b58a6df-4aae-4b9c-ed7a-da08c9e4dfb4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f1062e9d1f0>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.distributions import Categorical\n",
        "import gym\n",
        "from collections import deque\n",
        "import numpy as np\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.distributions import Categorical\n",
        "\n",
        "torch.manual_seed(0) # set random seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NjGmvVoe8ijA"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class Policy(nn.Module):\n",
        "    def __init__(self, s_size=6, h_size=32, a_size=3):\n",
        "        super(Policy, self).__init__()\n",
        "        self.fc1 = nn.Linear(s_size, h_size)\n",
        "        self.fc2 = nn.Linear(h_size, a_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return F.softmax(x, dim=1)\n",
        "    \n",
        "    def act(self, state):\n",
        "        state = torch.from_numpy(state).float().unsqueeze(0).to(device)\n",
        "        probs = self.forward(state).cpu()\n",
        "        m = Categorical(probs)\n",
        "        action = m.sample()\n",
        "        return action.item() - 1, m.log_prob(action)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make('Acrobot-v1')\n",
        "env.seed(0)\n",
        "print('observation space:', env.observation_space)\n",
        "print('action space:', env.action_space)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "policy = Policy().to(device)\n",
        "optimizer = optim.Adam(policy.parameters(), lr=0.001)\n",
        "\n",
        "def reinforce(n_episodes=5000, max_t=1000, gamma=1.0, print_every=100):\n",
        "    scores_deque = deque(maxlen=100)\n",
        "    scores = []\n",
        "    for i_episode in range(1, n_episodes+1):\n",
        "        saved_log_probs = []\n",
        "        rewards = []\n",
        "        state = env.reset()\n",
        "        for t in range(max_t):\n",
        "            action, log_prob = policy.act(state)\n",
        "            saved_log_probs.append(log_prob)\n",
        "            state, reward, done, _ = env.step(action)\n",
        "            rewards.append(reward)\n",
        "            if done:\n",
        "                break \n",
        "        scores_deque.append(sum(rewards))\n",
        "        scores.append(sum(rewards))\n",
        "        \n",
        "        discounts = [gamma**i for i in range(len(rewards)+1)]\n",
        "        R = sum([a*b for a,b in zip(discounts, rewards)])\n",
        "        \n",
        "        policy_loss = []\n",
        "        for log_prob in saved_log_probs:\n",
        "            policy_loss.append(-log_prob * R)\n",
        "        policy_loss = torch.cat(policy_loss).sum()\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        policy_loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if i_episode % print_every == 0:\n",
        "            torch.save(policy.state_dict(), 'checkpoint.pth')\n",
        "            print('Episode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_deque)))\n",
        "    \n",
        "    return scores\n",
        "\n",
        "scores = reinforce()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMWFP0zw8ojp",
        "outputId": "911b62fc-bcc8-4b5b-9606-4f0f6db211a4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.8/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.8/dist-packages/gym/core.py:256: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.\u001b[0m\n",
            "  deprecation(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "observation space: Box([ -1.        -1.        -1.        -1.       -12.566371 -28.274334], [ 1.        1.        1.        1.       12.566371 28.274334], (6,), float32)\n",
            "action space: Discrete(3)\n",
            "Episode 100\tAverage Score: -436.31\n",
            "Episode 200\tAverage Score: -427.93\n",
            "Episode 300\tAverage Score: -341.10\n",
            "Episode 400\tAverage Score: -271.18\n",
            "Episode 500\tAverage Score: -268.90\n",
            "Episode 600\tAverage Score: -250.07\n",
            "Episode 700\tAverage Score: -233.93\n",
            "Episode 800\tAverage Score: -227.49\n",
            "Episode 900\tAverage Score: -236.21\n",
            "Episode 1000\tAverage Score: -219.27\n",
            "Episode 1100\tAverage Score: -206.38\n",
            "Episode 1200\tAverage Score: -190.82\n",
            "Episode 1300\tAverage Score: -184.17\n",
            "Episode 1400\tAverage Score: -185.09\n",
            "Episode 1500\tAverage Score: -176.39\n",
            "Episode 1600\tAverage Score: -174.87\n",
            "Episode 1700\tAverage Score: -173.77\n",
            "Episode 1800\tAverage Score: -168.91\n",
            "Episode 1900\tAverage Score: -158.63\n",
            "Episode 2000\tAverage Score: -169.61\n",
            "Episode 2100\tAverage Score: -146.83\n",
            "Episode 2200\tAverage Score: -154.32\n",
            "Episode 2300\tAverage Score: -140.16\n",
            "Episode 2400\tAverage Score: -128.29\n",
            "Episode 2500\tAverage Score: -120.49\n",
            "Episode 2600\tAverage Score: -118.98\n",
            "Episode 2700\tAverage Score: -118.40\n",
            "Episode 2800\tAverage Score: -121.14\n",
            "Episode 2900\tAverage Score: -116.46\n",
            "Episode 3000\tAverage Score: -120.07\n",
            "Episode 3100\tAverage Score: -107.03\n",
            "Episode 3200\tAverage Score: -112.27\n",
            "Episode 3300\tAverage Score: -111.43\n",
            "Episode 3400\tAverage Score: -106.28\n",
            "Episode 3500\tAverage Score: -108.62\n",
            "Episode 3600\tAverage Score: -102.74\n",
            "Episode 3700\tAverage Score: -107.90\n",
            "Episode 3800\tAverage Score: -110.09\n",
            "Episode 3900\tAverage Score: -105.24\n",
            "Episode 4000\tAverage Score: -105.45\n",
            "Episode 4100\tAverage Score: -103.35\n",
            "Episode 4200\tAverage Score: -102.10\n",
            "Episode 4300\tAverage Score: -106.60\n",
            "Episode 4400\tAverage Score: -99.60\n",
            "Episode 4500\tAverage Score: -101.52\n",
            "Episode 4600\tAverage Score: -106.67\n",
            "Episode 4700\tAverage Score: -107.99\n",
            "Episode 4800\tAverage Score: -100.72\n",
            "Episode 4900\tAverage Score: -98.66\n",
            "Episode 5000\tAverage Score: -95.20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Визуализация"
      ],
      "metadata": {
        "id": "id8EbydVM8bj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gym[classic_control]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-gt0nXHBHhM",
        "outputId": "338a6fd2-6255-4930-eb4c-4a2840b6bb5e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gym[classic_control] in /usr/local/lib/python3.8/dist-packages (0.25.2)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.8/dist-packages (from gym[classic_control]) (4.13.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from gym[classic_control]) (1.5.0)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.8/dist-packages (from gym[classic_control]) (1.21.6)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.8/dist-packages (from gym[classic_control]) (0.0.8)\n",
            "Collecting pygame==2.1.0\n",
            "  Downloading pygame-2.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 18.3 MB 146 kB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.8.0->gym[classic_control]) (3.11.0)\n",
            "Installing collected packages: pygame\n",
            "Successfully installed pygame-2.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pygame\n",
        "from gym.wrappers.monitoring.video_recorder import VideoRecorder"
      ],
      "metadata": {
        "id": "yPxhmAVuM3ez"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pygame\n",
        "from gym.wrappers.monitoring.video_recorder import VideoRecorder\n",
        "\n",
        "state_dict = torch.load('checkpoint.pth')\n",
        "\n",
        "policy = Policy()\n",
        "policy.load_state_dict(state_dict)\n",
        "policy = policy.to(device)\n",
        "\n",
        "def show_smart_agent():\n",
        "    env = gym.make('Acrobot-v1')\n",
        "    recorder = VideoRecorder(env, path='./video.mp4')\n",
        "    state = env.reset()\n",
        "\n",
        "    for t in range(1000):\n",
        "        frame = env.render(mode='rgb_array')\n",
        "        recorder.capture_frame()\n",
        "\n",
        "        action, _ = policy.act(state)\n",
        "        state, reward, done, _ = env.step(action)\n",
        "      \n",
        "        if done:\n",
        "          break \n",
        "\n",
        "        time.sleep(0.05)\n",
        "\n",
        "    env.close()\n",
        "\n",
        "show_smart_agent()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIRi_DZY8wPQ",
        "outputId": "4616f591-e7d7-4c7e-f589-73b039d50d61"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.8/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.8/dist-packages/gym/wrappers/monitoring/video_recorder.py:78: DeprecationWarning: \u001b[33mWARN: Recording ability for environment Acrobot-v1 initialized with `render_mode=None` is marked as deprecated and will be removed in the future.\u001b[0m\n",
            "  logger.deprecation(\n",
            "/usr/local/lib/python3.8/dist-packages/gym/wrappers/monitoring/video_recorder.py:101: DeprecationWarning: \u001b[33mWARN: <class 'gym.wrappers.monitoring.video_recorder.VideoRecorder'> is marked as deprecated and will be removed in the future.\u001b[0m\n",
            "  logger.deprecation(\n",
            "/usr/local/lib/python3.8/dist-packages/gym/core.py:43: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  deprecation(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wql0e3i-BEgg"
      },
      "execution_count": 19,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}